service: csv-table-migration

package:
  individually: true

provider:
  name: aws
  runtime: python3.8
  region: us-east-2
  stage: ${opt:stage, "dev"}
  profile: giodragon
  memorySize: 128
  timeout: 30
  environment:
    S3_BUCKET: poc-gio
    S3_PATH: historic-upload
    TMP_FOLDER: /tmp/
    DB_CREDENTIALS: poc/historic-date/aurora-postgres
    SNS_TOPIC_ARN: arn:aws:sns:us-east-2:949778761636:insertion-csv
    DB_REGION: us-east-2
    INSERT_JOB_NAME: insert_avro_file_to_glue_database
  iam:
    role:
      statements:
        - Effect: "Allow"
          Action:
            - "s3:PutObject"
            - "s3:GetObject"
          Resource: "arn:aws:s3:::${self:provider.environment.S3_BUCKET}/${self:provider.environment.S3_PATH}*"

        - Effect: "Allow"
          Action:
            - "secretsmanager:*"
          Resource: "arn:aws:secretsmanager:${self:provider.environment.DB_REGION}:*:secret:${self:provider.environment.DB_CREDENTIALS}-hPlg7e"
        - Effect: "Allow"
          Action:
            - "sns:Publish"
          Resource: "${self:provider.environment.SNS_TOPIC_ARN}"
        - Effect: "Allow"
          Action:
            - "glue:StartJobRun"
          Resource: "arn:aws:glue:${self:provider.environment.DB_REGION}:*:job/${self:provider.environment.INSERT_JOB_NAME}"

plugins:
  - serverless-python-requirements

custom:
  pythonRequirements:
    dockerizePip: true
    layer:
      name: csv-table-migration
      description: CSV Table Migration
      compatibleRuntimes:
        - python3.8

functions:
  app:
    package:
      patterns:
        - "app/**"
        - "!requirements.txt"
        - "!package.json"
        - "!package-lock.json"
        - "!.gitignore"
        - "!.pre-commit-config.yaml"
        - "!.pylintrc"
        - "!.serverless/**"
        - "!node_modules/**"
        - "!ve/**"
        - "!migrate_files/**"
        - "!README.md"
        - "!glue_jobs/**"
        - "!trigger_restore_table/**"

    handler: app.main.handler
    environment:
        STAGE: ${self:provider.stage}
    layers:
      - { Ref: PythonRequirementsLambdaLayer }
    events:
      - http:
          method: any
          path: /{proxy+}
          cors: true

  migrate_files:
    package:
      patterns:
        - "migrate_files/**"
        - "!app/**"
        - "!requirements.txt"
        - "!package.json"
        - "!package-lock.json"
        - "!.gitignore"
        - "!.pre-commit-config.yaml"
        - "!.pylintrc"
        - "!.serverless/**"
        - "!node_modules/**"
        - "!ve/**"
        - "!README.md"
        - "!glue_jobs/**"
        - "!trigger_restore_table/**"

    handler: migrate_files.main.lambda_handler
    environment:
        STAGE: ${self:provider.stage}
    layers:
      - { Ref: PythonRequirementsLambdaLayer }
    events:
      - s3:
          bucket: ${self:provider.environment.S3_BUCKET}
          event: s3:ObjectCreated:Put
          rules:
            - prefix: historic-upload/
            - suffix: .csv
          existing: true

  restore_table:
    package:
      patterns:
        - "trigger_restore_table/**"
        - "!migrate_files/**"
        - "!app/**"
        - "!requirements.txt"
        - "!package.json"
        - "!package-lock.json"
        - "!.gitignore"
        - "!.pre-commit-config.yaml"
        - "!.pylintrc"
        - "!.serverless/**"
        - "!node_modules/**"
        - "!ve/**"
        - "!README.md"
        - "!glue_jobs/**"

    handler: trigger_restore_table_and_start_glue_job.main.lambda_handler
    environment:
        STAGE: ${self:provider.stage}
    layers:
      - { Ref: PythonRequirementsLambdaLayer }
